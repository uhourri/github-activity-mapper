{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4aac57d-4996-4d9c-8bcb-996fe89abc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    \"\"\"Loads a JSON file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def load_jsonl_file(file_path):\n",
    "    \"\"\"Loads a JSON Lines file and returns a list of records.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [json.loads(line) for line in file]\n",
    "\n",
    "def save_to_jsonl_file(data, file_path):\n",
    "    \"\"\"Saves a list of records to a JSON Lines file.\"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        for record in data:\n",
    "            json.dump(record, file)\n",
    "            file.write('\\n')\n",
    "\n",
    "# Define ActionMapper as described previously\n",
    "class ActivityProcessor:\n",
    "    def __init__(self, mapping):\n",
    "        self.mapping = mapping[\"activities\"]\n",
    "\n",
    "    def process_actions(self, actions):\n",
    "        actions = sorted(actions, key=lambda x: x['date'])\n",
    "        grouped_by_actor_repo = defaultdict(list)\n",
    "\n",
    "        for action in actions:\n",
    "            key = (action['actor']['id'], action['repository']['id'])\n",
    "            grouped_by_actor_repo[key].append(action)\n",
    "\n",
    "        grouped_activities = []\n",
    "        for key, group in grouped_by_actor_repo.items():\n",
    "            grouped_activities.extend(self.process_group(group))\n",
    "        return grouped_activities\n",
    "\n",
    "    def process_group(self, group):\n",
    "        activities = []\n",
    "        while group:\n",
    "            current_action = group.pop(0)\n",
    "            activity = self.match_activity(current_action, group)\n",
    "\n",
    "            if activity:\n",
    "                activities.append(activity)\n",
    "\n",
    "        return activities\n",
    "\n",
    "    def match_activity(self, action, remaining_actions):\n",
    "        for activity_def in self.mapping:\n",
    "            matched_actions = []\n",
    "            time_window = int(activity_def['time_window'].replace('s', ''))\n",
    "\n",
    "            for action_def in activity_def['actions']:\n",
    "                if action['action'] == action_def['action']:\n",
    "                    matched_actions.append(action)\n",
    "                    break\n",
    "\n",
    "            if not matched_actions:\n",
    "                continue\n",
    "\n",
    "            start_time = datetime.fromisoformat(action['date'])\n",
    "            for next_action in list(remaining_actions):\n",
    "                next_time = datetime.fromisoformat(next_action['date'])\n",
    "                if (next_time - start_time).total_seconds() > time_window:\n",
    "                    break\n",
    "\n",
    "                if self.is_action_valid(next_action, activity_def, matched_actions):\n",
    "                    matched_actions.append(next_action)\n",
    "                    remaining_actions.remove(next_action)\n",
    "\n",
    "            if not self.validate_required_actions(activity_def, matched_actions):\n",
    "                continue\n",
    "\n",
    "            return self.create_activity(activity_def, matched_actions)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def is_action_valid(self, action, activity_def, matched_actions):\n",
    "        for action_def in activity_def['actions']:\n",
    "            if action['action'] == action_def['action']:\n",
    "                if \"validate_with\" in action_def:\n",
    "                    return self.validate_with(action, matched_actions, action_def[\"validate_with\"])\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def validate_with(self, action, matched_actions, validation_rules):\n",
    "        for rule in validation_rules:\n",
    "            target_action = rule['target_action']\n",
    "            target_fields = rule['fields']\n",
    "\n",
    "            for matched_action in matched_actions:\n",
    "                if matched_action['action'] == target_action:\n",
    "                    for field_rule in target_fields:\n",
    "                        source_value = self.get_nested_value(action, field_rule['field'])\n",
    "                        target_value = self.get_nested_value(matched_action, field_rule['target_field'])\n",
    "\n",
    "                        if source_value != target_value:\n",
    "                            return False\n",
    "        return True\n",
    "\n",
    "    def validate_required_actions(self, activity_def, matched_actions):\n",
    "        required_actions = [a['action'] for a in activity_def['actions'] if not a['optional']]\n",
    "        matched_action_types = [a['action'] for a in matched_actions]\n",
    "        return all(req in matched_action_types for req in required_actions)\n",
    "\n",
    "    def create_activity(self, activity_def, matched_actions):\n",
    "        start_date = matched_actions[0]['date']\n",
    "        end_date = matched_actions[-1]['date']\n",
    "        actor = matched_actions[0]['actor']\n",
    "        repository = matched_actions[0]['repository']\n",
    "\n",
    "        for action in matched_actions:\n",
    "            del action['actor']\n",
    "            del action['repository']\n",
    "\n",
    "        return {\n",
    "            \"activity\": activity_def['name'],\n",
    "            \"start_date\": start_date,\n",
    "            \"end_date\": end_date,\n",
    "            \"actor\": actor,\n",
    "            \"repository\": repository,\n",
    "            \"actions\": matched_actions\n",
    "        }\n",
    "\n",
    "    def get_nested_value(self, obj, field_path):\n",
    "        keys = field_path.split('.')\n",
    "        for key in keys:\n",
    "            if isinstance(obj, dict):\n",
    "                obj = obj.get(key)\n",
    "            else:\n",
    "                return None\n",
    "        return obj\n",
    "\n",
    "# File Paths\n",
    "activity_mapping_file = '../data/mapping/action-activity-mapping.json'\n",
    "actions_file = '../data/test/actions/gh_all_actions.jsonl'\n",
    "activities_output_file = '../data/test/activities/gh_all_activities-v2.jsonl'\n",
    "\n",
    "# Process\n",
    "activity_mapping = load_json_file(activity_mapping_file)\n",
    "actions = load_jsonl_file(actions_file)\n",
    "mapper = ActivityProcessor(activity_mapping)\n",
    "activities = mapper.process_actions(actions)\n",
    "save_to_jsonl_file(activities, activities_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9196c-c468-4087-ab04-213a3025c5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009d2fd-e291-4ff6-b047-a53eb0de2439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9807de-ed60-423a-8161-10d6200f19ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "class ActivityProcessor:\n",
    "    def __init__(self, mapping_file):\n",
    "        with open(mapping_file, \"r\") as file:\n",
    "            self.mapping = json.load(file)\n",
    "\n",
    "    def process_actions(self, actions):\n",
    "        \"\"\"Process actions into activities based on the mapping.\"\"\"\n",
    "        grouped_actions = self.group_actions_by_actor_repo(actions)\n",
    "        all_activities = []\n",
    "\n",
    "        for (actor, repo), action_list in grouped_actions.items():\n",
    "            activities = self.build_activities(action_list)\n",
    "            all_activities.extend(activities)\n",
    "\n",
    "        return all_activities\n",
    "\n",
    "    def group_actions_by_actor_repo(self, actions):\n",
    "        \"\"\"Group actions by actor and repository.\"\"\"\n",
    "        grouped = defaultdict(list)\n",
    "        for action in actions:\n",
    "            key = (action['actor']['id'], action['repository']['id'])\n",
    "            grouped[key].append(action)\n",
    "        return grouped\n",
    "\n",
    "    def build_activities(self, actions):\n",
    "        \"\"\"Build activities from a list of actions.\"\"\"\n",
    "        actions.sort(key=lambda x: x['date'])  # Ensure actions are sorted by date\n",
    "        used_actions = set()\n",
    "        activities = []\n",
    "\n",
    "        for action in actions:\n",
    "            if action['event_id'] in used_actions:\n",
    "                continue\n",
    "\n",
    "            for activity_def in self.mapping['activities']:\n",
    "                matched_activity = self.match_activity(action, actions, activity_def, used_actions)\n",
    "                if matched_activity:\n",
    "                    activities.append(matched_activity)\n",
    "\n",
    "        return activities\n",
    "\n",
    "    def match_activity(self, base_action, actions, activity_def, used_actions):\n",
    "        \"\"\"Match an activity starting with the base action.\"\"\"\n",
    "        activity_actions = []\n",
    "        time_window = int(activity_def['time_window'].replace('s', ''))\n",
    "        start_time = datetime.strptime(base_action['date'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        end_time = start_time\n",
    "\n",
    "        for step in activity_def['actions']:\n",
    "            matched_steps = self.match_step(\n",
    "                base_action, actions, step, used_actions, start_time, time_window\n",
    "            )\n",
    "\n",
    "            if not matched_steps and not step['optional']:\n",
    "                return None  # Required step not matched\n",
    "\n",
    "            for matched_action in matched_steps:\n",
    "                if matched_action['event_id'] not in used_actions:\n",
    "                    activity_actions.append(matched_action)\n",
    "                    used_actions.add(matched_action['event_id'])\n",
    "\n",
    "                    # Extend end time\n",
    "                    action_time = datetime.strptime(matched_action['date'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                    end_time = max(end_time, action_time)\n",
    "\n",
    "        if activity_actions:\n",
    "            return {\n",
    "                \"activity\": activity_def['name'],\n",
    "                \"start_date\": base_action['date'],\n",
    "                \"end_date\": end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                \"actor\": base_action['actor'],\n",
    "                \"repository\": base_action['repository'],\n",
    "                \"actions\": activity_actions,\n",
    "            }\n",
    "\n",
    "        return None\n",
    "\n",
    "    def match_step(self, base_action, actions, step, used_actions, start_time, time_window):\n",
    "        \"\"\"Match a single step in the activity.\"\"\"\n",
    "        matched_actions = []\n",
    "\n",
    "        for action in actions:\n",
    "            if action['event_id'] in used_actions:\n",
    "                continue\n",
    "\n",
    "            # Validate action type\n",
    "            if action['action'] != step['action']:\n",
    "                continue\n",
    "\n",
    "            # Validate time window\n",
    "            action_time = datetime.strptime(action['date'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            if abs((action_time - start_time).total_seconds()) > time_window:\n",
    "                continue\n",
    "\n",
    "            # Validate fields\n",
    "            if 'validate_with' in step:\n",
    "                if not self.validate_action(action, base_action, step['validate_with']):\n",
    "                    continue\n",
    "\n",
    "            matched_actions.append(action)\n",
    "\n",
    "        return matched_actions if step['repeat'] else matched_actions[:1]\n",
    "\n",
    "    def validate_action(self, action, base_action, validations):\n",
    "        \"\"\"Validate an action using the validation rules.\"\"\"\n",
    "        for validation in validations:\n",
    "            for field_map in validation['fields']:\n",
    "                source_value = self.extract_field(action, field_map['field'])\n",
    "                target_value = self.extract_field(base_action, field_map['target_field'])\n",
    "                if source_value != target_value:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def extract_field(self, data, field_path):\n",
    "        \"\"\"Extract a nested field value from a dictionary.\"\"\"\n",
    "        keys = field_path.split('.')\n",
    "        for key in keys:\n",
    "            if not isinstance(data, dict):\n",
    "                return None\n",
    "            data = data.get(key)\n",
    "        return data\n",
    "\n",
    "# Example Usage\n",
    "actions = [\n",
    "    {\"action\": \"PushCommits\", \"event_id\": \"41517517158\", \"date\": \"2024-09-01T00:25:06Z\", \"actor\": {\"id\": 31115101, \"login\": \"lilyminium\"}, \"repository\": {\"id\": 518010502, \"name\": \"MDAnalysis/mdakit-cookie\", \"organisation\": \"MDAnalysis\", \"organisation_id\": 11445951}, \"details\": {\"push\": {\"id\": 20025231065, \"ref\": \"refs/heads/TestMDAKit_with_host_MDAnalysis_anaconda-deps_and_no-ReadTheDocs\", \"commits\": 1}}},\n",
    "    {\"action\": \"PushCommits\", \"event_id\": \"41517517041\", \"date\": \"2024-09-01T00:25:06Z\", \"actor\": {\"id\": 31115101, \"login\": \"lilyminium\"}, \"repository\": {\"id\": 518010502, \"name\": \"MDAnalysis/mdakit-cookie\", \"organisation\": \"MDAnalysis\", \"organisation_id\": 11445951}, \"details\": {\"push\": {\"id\": 20025231000, \"ref\": \"refs/heads/TestMDAKit_with_host_MDAnalysis_anaconda-deps_and_ReadTheDocs\", \"commits\": 1}}},\n",
    "    {\"action\": \"PushCommits\", \"event_id\": \"41517517306\", \"date\": \"2024-09-01T00:25:07Z\", \"actor\": {\"id\": 31115101, \"login\": \"lilyminium\"}, \"repository\": {\"id\": 518010502, \"name\": \"MDAnalysis/mdakit-cookie\", \"organisation\": \"MDAnalysis\", \"organisation_id\": 11445951}, \"details\": {\"push\": {\"id\": 20025231141, \"ref\": \"refs/heads/TestMDAKit_with_host_MDAnalysis_condaforge-deps_and_ReadTheDocs\", \"commits\": 1}}},\n",
    "    {\"action\": \"PushCommits\", \"event_id\": \"41517517456\", \"date\": \"2024-09-01T00:25:08Z\", \"actor\": {\"id\": 31115101, \"login\": \"lilyminium\"}, \"repository\": {\"id\": 518010502, \"name\": \"MDAnalysis/mdakit-cookie\", \"organisation\": \"MDAnalysis\", \"organisation_id\": 11445951}, \"details\": {\"push\": {\"id\": 20025231223, \"ref\": \"refs/heads/TestMDAKit_with_host_MDAnalysis_condaforge-deps_and_no-ReadTheDocs\", \"commits\": 1}}}\n",
    "]\n",
    "\n",
    "mapping_file = \"../data/mapping/action-activity-mapping.json\"\n",
    "\n",
    "processor = ActivityProcessor(mapping_file)\n",
    "grouped_activities = processor.process_actions(actions)\n",
    "\n",
    "print(json.dumps(grouped_activities, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42de02bf-cf11-43e3-818f-298a4988908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "class ActivityProcessor:\n",
    "    def __init__(self, mapping_file):\n",
    "        self.mapping = self.load_mapping(mapping_file)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_mapping(file_path):\n",
    "        \"\"\"Loads the activity mapping JSON file.\"\"\"\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "\n",
    "    def process_actions(self, actions):\n",
    "        \"\"\"Process actions into activities.\"\"\"\n",
    "        # Group actions by actor and repository\n",
    "        grouped_actions = defaultdict(list)\n",
    "        for action in actions:\n",
    "            key = (action['actor']['id'], action['repository']['id'])\n",
    "            grouped_actions[key].append(action)\n",
    "\n",
    "        # Process each group\n",
    "        activities = []\n",
    "        for (actor_id, repo_id), action_list in grouped_actions.items():\n",
    "            activities.extend(self.match_activities(action_list))\n",
    "\n",
    "        # Ensure all actions are consumed\n",
    "        consumed_action_ids = {a['event_id'] for act in activities for a in act['actions']}\n",
    "        unmatched_actions = [a for a in actions if a['event_id'] not in consumed_action_ids]\n",
    "        if unmatched_actions:\n",
    "            print(f\"Unmatched actions: {len(unmatched_actions)}\")\n",
    "        return activities\n",
    "\n",
    "    def match_activities(self, actions):\n",
    "        \"\"\"Match actions into activities.\"\"\"\n",
    "        actions = sorted(actions, key=lambda x: x['date'])  # Sort by date\n",
    "        activities = []\n",
    "        used_actions = set()\n",
    "\n",
    "        for action in actions:\n",
    "            if action['event_id'] in used_actions:\n",
    "                continue\n",
    "\n",
    "            # Match the activity starting with this action\n",
    "            matched_activity = self.match_activity(action, actions, used_actions)\n",
    "            if matched_activity:\n",
    "                activities.append(matched_activity)\n",
    "\n",
    "        return activities\n",
    "\n",
    "    def match_activity(self, base_action, actions, used_actions):\n",
    "        \"\"\"Match a single activity based on the base action.\"\"\"\n",
    "        for activity_def in self.mapping['activities']:\n",
    "            time_window = int(activity_def['time_window'].replace('s', ''))\n",
    "            start_time = datetime.strptime(base_action['date'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            end_time = start_time  # Initialize end_time for single-action activities\n",
    "            activity_actions = []\n",
    "\n",
    "            for step in activity_def['actions']:\n",
    "                matched_steps = self.match_step(\n",
    "                    base_action, actions, step, used_actions, start_time, time_window\n",
    "                )\n",
    "                if not matched_steps and not step['optional']:\n",
    "                    break  # Required step not matched, move to next activity definition\n",
    "                activity_actions.extend(matched_steps)\n",
    "\n",
    "            if activity_actions:\n",
    "                # Update end_time if multiple actions are matched\n",
    "                if len(activity_actions) > 1:\n",
    "                    end_time = max(\n",
    "                        datetime.strptime(a['date'], \"%Y-%m-%dT%H:%M:%SZ\") for a in activity_actions\n",
    "                    )\n",
    "                used_actions.update(a['event_id'] for a in activity_actions)\n",
    "                return {\n",
    "                    \"activity\": activity_def['name'],\n",
    "                    \"start_date\": start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                    \"end_date\": end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                    \"actor\": base_action['actor'],\n",
    "                    \"repository\": base_action['repository'],\n",
    "                    \"actions\": [\n",
    "                        {k: v for k, v in action.items() if k not in ['actor', 'repository']}\n",
    "                        for action in activity_actions\n",
    "                    ],\n",
    "                }\n",
    "\n",
    "        return None\n",
    "\n",
    "    def match_step(self, base_action, actions, step, used_actions, start_time, time_window):\n",
    "        \"\"\"Match a single step in an activity.\"\"\"\n",
    "        matched = []\n",
    "        for action in actions:\n",
    "            if action['event_id'] in used_actions:\n",
    "                continue\n",
    "            if action['action'] != step['action']:\n",
    "                continue\n",
    "\n",
    "            action_time = datetime.strptime(action['date'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            if abs((action_time - start_time).total_seconds()) > time_window:\n",
    "                continue\n",
    "\n",
    "            # Check validation rules, if any\n",
    "            if 'validate_with' in step:\n",
    "                for rule in step['validate_with']:\n",
    "                    if not self.validate_action(base_action, action, rule):\n",
    "                        break\n",
    "                else:\n",
    "                    matched.append(action)\n",
    "            else:\n",
    "                matched.append(action)\n",
    "\n",
    "            if not step['repeat']:\n",
    "                break  # Only allow one match for non-repeating steps\n",
    "\n",
    "        return matched\n",
    "\n",
    "    def validate_action(self, base_action, target_action, rule):\n",
    "        \"\"\"Validate an action based on a rule.\"\"\"\n",
    "        for field_map in rule['fields']:\n",
    "            base_value = self.extract_field(base_action, field_map['field'])\n",
    "            target_value = self.extract_field(target_action, field_map['target_field'])\n",
    "            if base_value != target_value:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_field(record, field_path):\n",
    "        \"\"\"Extracts a field value from a nested record.\"\"\"\n",
    "        fields = field_path.split('.')\n",
    "        for field in fields:\n",
    "            record = record.get(field)\n",
    "            if record is None:\n",
    "                return None\n",
    "        return record\n",
    "\n",
    "# File Paths\n",
    "activity_mapping_file = '../data/mapping/action-activity-mapping.json'\n",
    "actions_file = '../data/test/actions/gh_all_actions.jsonl'\n",
    "activities_output_file = '../data/test/activities/gh_all_activities-v5.jsonl'\n",
    "\n",
    "# Load actions\n",
    "actions = load_jsonl_file(actions_file)\n",
    "\n",
    "# Process actions\n",
    "processor = ActivityProcessor(activity_mapping_file)\n",
    "grouped_activities = processor.process_actions(actions)\n",
    "\n",
    "# Save the resulting activities\n",
    "save_to_jsonl_file(grouped_activities, activities_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6462a-3741-4051-b4aa-51452e358160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
