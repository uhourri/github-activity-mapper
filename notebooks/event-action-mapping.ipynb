{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f88b0118-f0b7-4201-b1c0-10003692e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from datetime import datetime, timezone\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52c23a98-3979-4d74-afc5-6dada067534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventMapper:\n",
    "    def __init__(self, action_mapping):\n",
    "        self.action_mapping = action_mapping\n",
    "\n",
    "    def deserialize_payload(self, event_record):\n",
    "        \"\"\"Deserializes the 'payload' field of the event record if it's a string.\"\"\"\n",
    "        event_record['payload'] = json.loads(event_record['payload'])\n",
    "        return event_record\n",
    "    \n",
    "    def convert_date_to_iso(self, event_record):\n",
    "        \"\"\"Converts 'date' field from Unix timestamp to ISO 8601 format.\"\"\"\n",
    "        event_record['created_at'] = datetime.fromtimestamp(event_record['created_at']/1000, tz=timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        return event_record\n",
    "\n",
    "    def match_condition(self, event_value, mapping_value):\n",
    "        \"\"\"Matches an event value against a mapping value, supporting regex and nested matching.\"\"\"\n",
    "        if isinstance(mapping_value, dict):\n",
    "            return all(self.match_condition(event_value.get(k), v) for k, v in mapping_value.items() if k in event_value)\n",
    "        \n",
    "        if isinstance(mapping_value, list):\n",
    "            return all(self.match_condition(ev, mv) for ev, mv in zip(event_value, mapping_value)) if event_value else False\n",
    "\n",
    "        if isinstance(mapping_value, str) and mapping_value.startswith('^') and mapping_value.endswith('$'):\n",
    "            return bool(re.match(mapping_value, event_value))\n",
    "        \n",
    "        return event_value == mapping_value\n",
    "\n",
    "    def map_event_to_action(self, event_record):\n",
    "        \"\"\"Maps an event to a high-level action based on event type and attributes.\"\"\"\n",
    "        event_record = self.deserialize_payload(event_record)\n",
    "        event_record = self.convert_date_to_iso(event_record)\n",
    "        event_type = event_record.get('type')\n",
    "\n",
    "        for action_name, action_details in self.action_mapping['actions'].items():\n",
    "            if event_type == action_details['event']['type'] and \\\n",
    "               all(self.match_condition(self.extract_field(event_record, k), v) \n",
    "                   for k, v in action_details['event'].items() if k != 'type'):\n",
    "                return self.extract_attributes(event_record, action_details, action_name)\n",
    "\n",
    "        return self.extract_attributes(event_record, self.action_mapping['actions']['UnknownAction'], 'UnknownAction')\n",
    "\n",
    "    def extract_attributes(self, event_record, action_details, action_name):\n",
    "        \"\"\"Extracts attributes and common fields from the event record.\"\"\"\n",
    "        mapped_action = {'action': action_name}\n",
    "\n",
    "        if action_details['attributes'].get('include_common_fields'):\n",
    "            mapped_action.update(self.extract_fields(event_record, self.action_mapping['common_fields']))\n",
    "\n",
    "        mapped_action['details'] = self.extract_fields(event_record, action_details['attributes'].get('details', {}))\n",
    "\n",
    "        return mapped_action\n",
    "\n",
    "    def extract_fields(self, event_record, field_mapping):\n",
    "        \"\"\"Extracts values based on the provided mapping, handling nested dictionaries and lists.\"\"\"\n",
    "        extracted_data = {}\n",
    "\n",
    "        for field_key, mapping_value in field_mapping.items():\n",
    "            if isinstance(mapping_value, dict):\n",
    "                extracted_data[field_key] = self.extract_fields(event_record, mapping_value)\n",
    "            elif isinstance(mapping_value, list):\n",
    "                extracted_data[field_key] = self.extract_list(event_record, mapping_value)\n",
    "            else:\n",
    "                extracted_data[field_key] = self.extract_field(event_record, mapping_value)\n",
    "\n",
    "        return extracted_data\n",
    "\n",
    "    def extract_list(self, event_record, list_mapping):\n",
    "        \"\"\"Handles extracting lists of values from the event record.\"\"\"\n",
    "        base_list = self.extract_field(event_record, list_mapping[0][list(list_mapping[0].keys())[0]].split('.')[0:-1])\n",
    "        if not isinstance(base_list, list):\n",
    "            return []\n",
    "\n",
    "        return [{key: item.get(path.split('.')[-1], None) for key, path in list_mapping[0].items()} for item in base_list]\n",
    "\n",
    "    def extract_field(self, event_record, field_path):\n",
    "        \"\"\"Extracts a value from the event record using a dotted field path.\"\"\"\n",
    "        keys = field_path.split('.') if isinstance(field_path, str) else field_path\n",
    "        value = event_record\n",
    "        for key in keys:\n",
    "            if isinstance(value, list):\n",
    "                return value\n",
    "            value = value.get(key)\n",
    "            if value is None:\n",
    "                return None\n",
    "\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41ca773d-d55b-4f0c-a6e2-0cf490fedda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(file_path):\n",
    "    \"\"\"Loads a JSON file from the provided file path.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31386094-891a-497e-a5c3-171814ce6f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_event_files(input_folder, output_folder, combined_output_file, mapping_file):\n",
    "    \"\"\"Reads event data, processes them in chronological order, and saves the resulting actions into individual JSON Lines files and a single combined JSON Lines file.\"\"\"\n",
    "\n",
    "    action_mapping = load_json_file(mapping_file)\n",
    "    event_mapper = EventMapper(action_mapping)\n",
    "\n",
    "    # Get and sort event files by filename (chronological order based on YYYYMM format)\n",
    "    event_files = sorted(\n",
    "        [f for f in os.listdir(input_folder) if f.startswith('gh_events') and f.endswith('.json')]\n",
    "    )\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Open the combined output file in write mode to append each line\n",
    "    with open(combined_output_file, 'w') as combined_file:\n",
    "        for event_file in event_files:\n",
    "            # Extract year-month from the event filename (e.g., gh_events_202301.json -> 202301)\n",
    "            year_month = event_file.split('_')[2].split('.')[0]\n",
    "\n",
    "            input_file_path = os.path.join(input_folder, event_file)\n",
    "            event_records = load_json_file(input_file_path)\n",
    "\n",
    "            # Map events to actions\n",
    "            mapped_actions = [event_mapper.map_event_to_action(event_record) for event_record in event_records]\n",
    "\n",
    "            # Write each action to the individual JSON Lines file\n",
    "            output_file_path = os.path.join(output_folder, f\"gh_actions_{year_month}.jsonl\")\n",
    "            with open(output_file_path, 'w') as monthly_file:\n",
    "                for action in mapped_actions:\n",
    "                    json.dump(action, monthly_file)\n",
    "                    monthly_file.write('\\n')  # JSON Lines format requires a newline after each record\n",
    "\n",
    "                    # Also write to the combined file\n",
    "                    json.dump(action, combined_file)\n",
    "                    combined_file.write('\\n')\n",
    "\n",
    "            print(f\"Processed {event_file} -> {output_file_path}\")\n",
    "\n",
    "    print(f\"All processed actions saved to {combined_output_file} in JSON Lines format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1360631f-c4c6-4fb0-b7a0-aa2d9a0e5cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed gh_events_202301.json -> ../data/datasets/actions/monthly/gh_actions_202301.jsonl\n",
      "Processed gh_events_202302.json -> ../data/datasets/actions/monthly/gh_actions_202302.jsonl\n",
      "Processed gh_events_202303.json -> ../data/datasets/actions/monthly/gh_actions_202303.jsonl\n",
      "Processed gh_events_202304.json -> ../data/datasets/actions/monthly/gh_actions_202304.jsonl\n",
      "Processed gh_events_202305.json -> ../data/datasets/actions/monthly/gh_actions_202305.jsonl\n",
      "Processed gh_events_202306.json -> ../data/datasets/actions/monthly/gh_actions_202306.jsonl\n",
      "Processed gh_events_202307.json -> ../data/datasets/actions/monthly/gh_actions_202307.jsonl\n",
      "Processed gh_events_202308.json -> ../data/datasets/actions/monthly/gh_actions_202308.jsonl\n",
      "Processed gh_events_202309.json -> ../data/datasets/actions/monthly/gh_actions_202309.jsonl\n",
      "Processed gh_events_202310.json -> ../data/datasets/actions/monthly/gh_actions_202310.jsonl\n",
      "Processed gh_events_202311.json -> ../data/datasets/actions/monthly/gh_actions_202311.jsonl\n",
      "Processed gh_events_202312.json -> ../data/datasets/actions/monthly/gh_actions_202312.jsonl\n",
      "Processed gh_events_202401.json -> ../data/datasets/actions/monthly/gh_actions_202401.jsonl\n",
      "Processed gh_events_202402.json -> ../data/datasets/actions/monthly/gh_actions_202402.jsonl\n",
      "Processed gh_events_202403.json -> ../data/datasets/actions/monthly/gh_actions_202403.jsonl\n",
      "Processed gh_events_202404.json -> ../data/datasets/actions/monthly/gh_actions_202404.jsonl\n",
      "Processed gh_events_202405.json -> ../data/datasets/actions/monthly/gh_actions_202405.jsonl\n",
      "Processed gh_events_202406.json -> ../data/datasets/actions/monthly/gh_actions_202406.jsonl\n",
      "Processed gh_events_202407.json -> ../data/datasets/actions/monthly/gh_actions_202407.jsonl\n",
      "Processed gh_events_202408.json -> ../data/datasets/actions/monthly/gh_actions_202408.jsonl\n",
      "Processed gh_events_202409.json -> ../data/datasets/actions/monthly/gh_actions_202409.jsonl\n",
      "All processed actions saved to ../data/datasets/actions/gh_all_actions.jsonl in JSON Lines format.\n"
     ]
    }
   ],
   "source": [
    "input_folder = '../data/datasets/pre-processed-v2'\n",
    "output_folder = '../data/datasets/actions/monthly'\n",
    "combined_output_file = '../data/datasets/actions/gh_all_actions.jsonl'\n",
    "mapping_file = '../data/mapping/event-action-mapping.json'\n",
    "\n",
    "process_event_files(input_folder, output_folder, combined_output_file, mapping_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d95c5-b2df-4ac2-8d18-6db0805f7bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
